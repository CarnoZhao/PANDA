{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/data/zhaoxun/miniconda3/envs/torch/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import h5py\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "import PoolTileNet\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# TRAIN = \"/home/zhaoxun/codes/Panda/_data/iafoss/train\"\n",
    "# LABELS = '/home/zhaoxun/codes/Panda/_data/train.csv'\n",
    "\n",
    "\n",
    "class PngData(object):\n",
    "    def __init__(self, TRAIN = \"/home/zhaoxun/codes/Panda/_data/iafoss/train\", LABELS = '/home/zhaoxun/codes/Panda/_data/train.csv', N = 12, size = 128):\n",
    "        self.TRAIN = TRAIN\n",
    "        self.mean = torch.tensor([1.0 - 0.90949707, 1.0 - 0.8188697, 1.0 - 0.87795304])[..., None, None]\n",
    "        self.std = torch.tensor([0.36357649, 0.49984502, 0.40477625])[..., None, None]\n",
    "        self.sz = size\n",
    "        self.N = N\n",
    "\n",
    "        nfolds = 5\n",
    "        df = pd.read_csv(LABELS).set_index('image_id')\n",
    "        files = sorted(set([p[:32] for p in os.listdir(TRAIN)]))\n",
    "        df = df.loc[files]\n",
    "        df = df.reset_index()\n",
    "        splits = StratifiedKFold(n_splits = nfolds, random_state =1, shuffle =True)\n",
    "        splits = list(splits.split(df, df.isup_grade))\n",
    "        folds_splits = np.zeros(len(df)).astype(np.int)\n",
    "        for i in range(nfolds):\n",
    "            folds_splits[splits[i][1]] = i\n",
    "        df['split'] = folds_splits\n",
    "        self.df = df\n",
    "\n",
    "    @classmethod\n",
    "    def open_image(cls, fn, div = True, convert_mode = 'RGB', imcls = Image, after_open = None):\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", UserWarning)\n",
    "            x = PIL.Image.open(fn).convert(convert_mode)\n",
    "        if after_open:\n",
    "            x = after_open(x)\n",
    "        x = pil2tensor(x, np.float32)\n",
    "        if div: x.div_(255)\n",
    "        return imcls(1.0 - x)\n",
    "\n",
    "    @property\n",
    "    def MyImage(self):\n",
    "        outter = self\n",
    "        class _MyImage(ItemBase):\n",
    "            def __init__(self, imgs):\n",
    "                self.obj = (imgs)\n",
    "                self.data = [(img.data - outter.mean) / outter.std for img in imgs]\n",
    "\n",
    "            def __repr__(self): \n",
    "                return f'{self.__class__.__name__} {[img.shape for img in self.obj]}'\n",
    "\n",
    "            def apply_tfms(self, tfms, *args, **kwargs):\n",
    "                for i in range(len(self.obj)):\n",
    "                    self.obj[i] = self.obj[i].apply_tfms(tfms, *args, **kwargs)\n",
    "                    self.data[i] = (self.obj[i].data - outter.mean) / outter.std\n",
    "                return self\n",
    "\n",
    "            def to_one(self):\n",
    "                img = torch.stack(self.data, 1)\n",
    "                img = (img\n",
    "                    .view(3, -1, outter.N, outter.sz, outter.sz)\n",
    "                    .permute(0, 1, 3, 2, 4)\n",
    "                    .contiguous()\n",
    "                    .view(3, -1, outter.sz, outter.N))\n",
    "                return Image(1.0 - (outter.mean + img * outter.std))\n",
    "        return _MyImage\n",
    "\n",
    "    @property\n",
    "    def MyImageItemList(self):\n",
    "        outter = self\n",
    "        class _MyImageItemList(ImageList):\n",
    "            def __init__(self, *args, **kwargs):\n",
    "                super().__init__(*args, **kwargs)\n",
    "\n",
    "            def __len__(self): \n",
    "                return len(self.items) or 1\n",
    "\n",
    "            def get(self, i):\n",
    "                fn = Path(self.items[i])\n",
    "                fnames = [Path(\"%s_%d.png\" % (fn, i)) for i in range(outter.N)]\n",
    "                imgs = [outter.open_image(fname, convert_mode = self.convert_mode, after_open = self.after_open) for fname in fnames]\n",
    "                return outter.MyImage(imgs)\n",
    "\n",
    "            def reconstruct(self, t):\n",
    "                return outter.MyImage([outter.mean + ti * outter.std for ti in t])\n",
    "\n",
    "            def show_xys(self, xs, ys, figsize = (300, 50), **kwargs):\n",
    "                rows = min(len(xs), 8)\n",
    "                fig, axs = plt.subplots(rows, 1, figsize = figsize)\n",
    "                for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n",
    "                    xs[i].to_one().show(ax = ax, y = ys[i], **kwargs)\n",
    "                plt.tight_layout()\n",
    "        return _MyImageItemList\n",
    "\n",
    "    # collate function to combine multiple images into one tensor\n",
    "    def MImage_collate(self, batch) -> Tensor:\n",
    "        result = torch.utils.data.dataloader.default_collate(to_data(batch))\n",
    "        if isinstance(result[0], list):\n",
    "            result = [torch.stack(result[0], 1), result[1]]\n",
    "        return result\n",
    "\n",
    "    def get_data(self, bs, bg = None, br = 0.8):\n",
    "        trainidx = self.df.index[self.df.split != 0].tolist()\n",
    "        if bg is not None: trainidx = np.random.choice(trainidx, round(len(trainidx) * br), replace = False)\n",
    "        validx = self.df.index[self.df.split == 0].tolist()\n",
    "        return (self.MyImageItemList.from_df(self.df, path = '/', folder = self.TRAIN, cols = 'image_id')\n",
    "                .split_by_idxs(trainidx, validx)\n",
    "                .label_from_df(cols = ['isup_grade'])\n",
    "                .transform(get_transforms(flip_vert = True, max_rotate = 15), size = self.sz, padding_mode = 'zeros')\n",
    "                .databunch(bs = bs, num_workers = 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "        self.data = PngData()\n",
    "\n",
    "        # model\n",
    "        self.load_net()\n",
    "\n",
    "        # loss\n",
    "        if kwargs['ls'] == \"focal\":\n",
    "            self.loss = PoolTileNet.FocalSmoothLoss(kwargs['nc'], kwargs['sm'], kwargs['gm'])\n",
    "        elif kwargs['ls'] == \"cross\":\n",
    "            self.loss = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        if kwargs['op'] == \"sgd\":\n",
    "            self.opt = torch.optim.SGD\n",
    "        elif kwargs['op'] == \"adam\":\n",
    "            self.opt = RAdam\n",
    "        elif kwargs['op'] == \"over\":\n",
    "            self.opt = Over9000\n",
    "\n",
    "    def load_net(self):\n",
    "        if self.kwargs['nt'] == \"resnet34\":\n",
    "            self.net = PoolTileNet.PoolTileNetList(self.kwargs[\"nc\"])\n",
    "        elif self.kwargs['nt'] == \"resnext50\":\n",
    "            self.net = PoolTileNet.SemiResNextList(n = self.kwargs['nc'])\n",
    "        elif self.kwargs['nt'] == \"eff\":\n",
    "            self.net = PoolTileNet.MyEfficientNet(self.kwargs['nc'])\n",
    "        self.net = self.net.cuda()\n",
    "        if self.kwargs['MD']:\n",
    "            dic = torch.load(self.kwargs['MD'])\n",
    "            self.net.load_state_dict(dic)\n",
    "\n",
    "    def callback_bak(self, i, loss, valloader):\n",
    "        self.losses[\"train\"].append(loss)\n",
    "        self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            valloss = 0; valcnt = 0\n",
    "            for x, y in tqdm.tqdm(valloader, desc = \"Validating...\", leave = False, mininterval = 60):\n",
    "                x = x.cuda(); y = y.cuda()\n",
    "                yhat = self.net(x)\n",
    "                cost = self.loss(yhat, y.long())\n",
    "                valloss += cost.item() * len(x); valcnt += len(x)\n",
    "            self.losses[\"val\"].append(valloss / valcnt)\n",
    "        printOut(\"{:3d} | tr: {:.3f} | vl: {:.3f}\".format(i, loss, valloss / valcnt))\n",
    "        return valloss / valcnt\n",
    "\n",
    "    class callback(LearnerCallback):\n",
    "        def __init__(self, ln):\n",
    "            self.ln = ln\n",
    "            self.losses = {\"train\": [], \"val\": []}\n",
    "            \n",
    "\n",
    "        @property\n",
    "        def header(self):\n",
    "            return self.ln.recorder.names\n",
    "\n",
    "        def on_epoch_end(self, epoch, smooth_loss, last_metrics, **kwargs):\n",
    "            self.losses['train'].append(float(smooth_loss))\n",
    "            self.losses['val'].append(float(last_metrics[0]))\n",
    "            self.write_stats([epoch, smooth_loss] + last_metrics)\n",
    "\n",
    "        def write_stats(self, stats):\n",
    "            printOut(\"{:3d} | tr: {:.3f} | vl: {:.3f} | kp: {:.3f}\".format(*stats))\n",
    "\n",
    "        def on_train_end(self, **kwargs):\n",
    "            plt.plot(self.losses['train'], label = \"train\")\n",
    "            plt.plot(self.losses['val'], label = \"val\")\n",
    "            plt.legend()\n",
    "            plt.savefig(plotpath)\n",
    "\n",
    "    def evaluations_bak(self, trainloader, valloader):\n",
    "        K = self.kwargs['nc']\n",
    "        with torch.no_grad():\n",
    "            self.net.eval()\n",
    "            for i, loader in enumerate((trainloader, valloader)):\n",
    "                Y = np.zeros(len(loader.dataset), dtype = np.int); Yhat = np.zeros(len(loader.dataset), dtype = np.int); idx = 0\n",
    "                for x, y in tqdm.tqdm(loader, desc = \"Evaluating...\", leave = False, mininterval = 60):\n",
    "                    x = x.cuda(); y = y.numpy()\n",
    "                    yhat = self.net(x).argmax(1).cpu().data.numpy()\n",
    "                    Y[idx:idx + len(y)] = y; Yhat[idx:idx + len(y)] = yhat; idx += len(y)\n",
    "                printOut([\"Train\", \"Val\"][i] + \" kappa: %.4f\" % (metrics.cohen_kappa_score(Y, Yhat, weights = \"quadratic\")))\n",
    "                printOut([\"Train\", \"Val\"][i] + \":\\n\" + str(metrics.confusion_matrix(Y, Yhat)))\n",
    "                printOut(\"\\n~~~~~\\n\")\n",
    "        plt.plot(self.losses['train'], label = \"train\")\n",
    "        plt.plot(self.losses['val'], label = \"val\")\n",
    "        plt.legend()\n",
    "        plt.savefig(plotpath)\n",
    "\n",
    "    def evaluations(self, ln):\n",
    "        pred,target = [],[]\n",
    "        ln.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for step, (x, y) in progress_bar(enumerate(ln.data.dl(DatasetType.Valid)), total=len(ln.data.dl(DatasetType.Valid))):\n",
    "                p = ln.model(*x)\n",
    "                pred.append(p.float().cpu())\n",
    "                target.append(y.cpu())\n",
    "        p = torch.argmax(torch.cat(pred, 0), 1)\n",
    "        t = torch.cat(target)\n",
    "        printOut(\"Val kappa: %.5f\" % cohen_kappa_score(t, p, weights = 'quadratic'))\n",
    "        printOut(confusion_matrix(t, p))\n",
    "\n",
    "    def bag_eval(self):\n",
    "        pred,target = [],[]\n",
    "        dirpath = modelpath + \"s\"\n",
    "        dl = self.data.get_data(self.kwargs['bs'], 0, self.kwargs['br'])\n",
    "        for bag in range(self.kwargs['bg']):\n",
    "            self.net.load_state_dict(torch.load(os.path.join(dirpath, \"model.%d.pth\" % bag)))\n",
    "            ln = Learner(dl, self.net, loss_func = self.loss, opt_func = self.opt, metrics = [KappaScore(weights = 'quadratic')], bn_wd = False, wd = self.kwargs['wd']).to_fp16()\n",
    "            ln.model.eval()\n",
    "            with torch.no_grad():\n",
    "                for step, (x, y) in progress_bar(enumerate(ln.data.dl(DatasetType.Valid)), total=len(ln.data.dl(DatasetType.Valid))):\n",
    "                    p = ln.model(*x)\n",
    "                    if len(pred) == step: \n",
    "                        pred.append(p.float().cpu())\n",
    "                        target.append(y.cpu())\n",
    "                    else:\n",
    "                        pred[step] += p.float().cpu()\n",
    "        p = torch.argmax(torch.cat(pred, 0), 1)\n",
    "        t = torch.cat(target)\n",
    "        printOut(\"Val kappa: %.5f\" % cohen_kappa_score(t, p, weights = 'quadratic'))\n",
    "        printOut(confusion_matrix(t, p))\n",
    "\n",
    "    def train_bak(self):\n",
    "        trainloader, valloader = self.data.toLoader(self.kwargs['bs'])\n",
    "        for i in tqdm.tqdm(range(1, self.kwargs['ep'] + 1), desc = \"Iterating...\", mininterval = 60):\n",
    "            self.net.train()    \n",
    "            loss = 0; cnt = 0\n",
    "            for x, y in tqdm.tqdm(trainloader, desc = \"Training...\", leave = False, mininterval = 60):\n",
    "                x = x.cuda(); y = y.cuda()\n",
    "                yhat = self.net(x)\n",
    "                cost = self.loss(yhat, y.long())\n",
    "                loss += cost.item() * len(x); cnt += len(x)\n",
    "                self.opt.zero_grad()\n",
    "                cost.backward()\n",
    "                self.opt.step()\n",
    "            valloss = self.callback(i, loss / cnt, valloader)\n",
    "            self.sch.step(valloss)\n",
    "        torch.save(self.net.state_dict(), modelpath)\n",
    "        self.evaluations(trainloader, valloader)\n",
    "\n",
    "    def train(self, dl = None):\n",
    "        dl = self.data.toLoader(self.kwargs['bs']) if dl is None else dl\n",
    "        ln = Learner(dl, self.net, loss_func = self.loss, opt_func = self.opt, metrics = [KappaScore(weights = 'quadratic')], bn_wd = False, wd = self.kwargs['wd']).to_fp16()\n",
    "        ln.clip_grad = 1.0\n",
    "        ln.split([self.net.head])\n",
    "        ln.unfreeze()\n",
    "        cb = self.callback(ln)\n",
    "        ln.fit_one_cycle(self.kwargs['ep'], max_lr = self.kwargs['lr'], div_factor = self.kwargs['df'], pct_start = 0.0, wd = self.kwargs['wd'], callbacks = [cb])\n",
    "        torch.save(self.net.state_dict(), modelpath)\n",
    "        self.evaluations(ln)\n",
    "\n",
    "    def bag_train(self):\n",
    "        dirpath = modelpath + \"s\"\n",
    "        os.system(\"mkdir -p %s\" % dirpath)\n",
    "        for bag in range(self.kwargs['bg']):\n",
    "            dl = self.data.get_data(self.kwargs['bs'], bag, self.kwargs['br'])\n",
    "            self.load_net()\n",
    "            self.train(dl)\n",
    "            os.system(\"mv %s %s\" % (modelpath, os.path.join(dirpath, \"model.%d.pth\" % bag)))\n",
    "        self.bag_eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-f\", \"--h5\", help = \"h5 file path\", default = \"/home/zhaoxun/codes/Panda/_data/v0.h5\", type = str)\n",
    "    parser.add_argument(\"-M\", \"--MD\", help = \"model file\", default = \"\", type = str)\n",
    "    parser.add_argument(\"-N\", \"--nt\", help = \"net type\", default = \"resnet34\", choices = [\"resnet34\", \"resnext50\", \"eff\"], type = str)\n",
    "    parser.add_argument(\"-e\", \"--ep\", help = \"number of epochs\", default = 5, type = int)\n",
    "    parser.add_argument(\"-n\", \"--nc\", help = \"number of classes\", default = 6, type = int)\n",
    "    # parser.add_argument(\"-p\", \"--pt\", help = \"pretrained\", default = True, type = bool)\n",
    "    parser.add_argument(\"-l\", \"--lr\", help = \"learning rate\", default = 1e-3, type = float)\n",
    "    parser.add_argument(\"-L\", \"--ls\", help = \"loss type\", default = \"cross\", choices = [\"cross\", \"focal\"], type = str)\n",
    "    parser.add_argument(\"-b\", \"--bs\", help = \"batch size\", default = 32, type = int)\n",
    "    # parser.add_argument(\"-c\", \"--cb\", help = \"call-back step size\", default = 1, type = int)\n",
    "    # parser.add_argument(\"-s\", \"--ss\", help = \"learning rate scheduler step size\", default = 30, type = int)\n",
    "    parser.add_argument(\"-w\", \"--wd\", help = \"weight decay\", default = 1e-3, type = float)\n",
    "    # parser.add_argument(\"-g\", \"--gp\", help = \"gpus\", default = [0], type = list)\n",
    "    parser.add_argument(\"-d\", \"--dv\", help = \"visible devices\", default = \"3\", choices = list(\"0123\"), type = str)\n",
    "    parser.add_argument(\"-s\", \"--sm\", help = \"label smoothing\", default = 0.001, type = float)\n",
    "    parser.add_argument(\"-m\", \"--gm\", help = \"focal loss gamma\", default = 2, type = int)\n",
    "    parser.add_argument(\"-o\", \"--op\", help = \"optim method\", default = \"sgd\", choices = [\"sgd\", \"adam\", \"over\"], type = str)\n",
    "    parser.add_argument(\"-v\", \"--df\", help = \"divide factor\", default = 100, type = int)\n",
    "    parser.add_argument(\"-B\", \"--bg\", help = \"bag iters\", default = 0, type = int)\n",
    "    parser.add_argument(\"-R\", \"--br\", help = \"bag ratio\", default = 0.8, type = float)\n",
    "    # parser.add_argument(\"-S\", \"--sc\", help = \"learning rate scheduler\", default = \"cos\", type = str)\n",
    "    return vars(parser.parse_args())\n",
    "params = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Train(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = t\n",
    "dl = self.data.get_data(self.kwargs['bs'])\n",
    "ln = Learner(dl, self.net, loss_func = self.loss, opt_func = self.opt, metrics = [KappaScore(weights = 'quadratic')], bn_wd = False, wd = self.kwargs['wd']).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>kappa_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='92' class='' max='262' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      35.11% [92/262 00:51<01:34 7.7623]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "ln.model_dir = \"/home/zhaoxun/codes/Panda/models\"\n",
    "ln.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ln.recorder.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
